{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NECESSARY IMPORTS\n",
    "import numpy, scipy, pandas as pd\n",
    "from scipy.io.arff import loadarff\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# FOR DIMENSION REDUCTION, CLASSIFICATION MODEL AND CLUSTERING\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# FOR MAKING NETWORK AND OTHER STUFFS\n",
    "import networkx as nx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING TRAINING DATASET AND TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train_f = \"DataSets/Earthquakes/Earthquakes_TRAIN.arff\" # PATH TO TRAINING DATASET\n",
    "e_test_f = \"DataSets/Earthquakes/Earthquakes_TEST.arff\" # PATH TO TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train, e_train_meta = loadarff(e_train_f)\n",
    "df = pd.DataFrame(e_train)\n",
    "\n",
    "# SEPERATING THE DATA AND CLASS LABEL\n",
    "dataa = df.iloc[:, :-1]\n",
    "tagg = df.iloc[:, -1:] # IN THE arff FILE, THE LAST COLUMN IS THE CLASS LABEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_test, e_test_meta = loadarff(e_test_f)\n",
    "df_test = pd.DataFrame(e_test)\n",
    "\n",
    "# SEPERATING THE DATA AND CLASS LABEL\n",
    "dataa_test = df_test.iloc[:, :-1]\n",
    "tagg_test = df_test.iloc[:, -1:] # IN THE arff FILE, THE LAST COLUMN IS THE CLASS LABEL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagg = tagg.replace(b'1', 1)\n",
    "tagg = tagg.replace(b'0', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagg_test = tagg_test.replace(b'1', 1)\n",
    "tagg_test = tagg_test.replace(b'0', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(dataa)\n",
    "y_train = np.array(tagg)\n",
    "\n",
    "x_test = np.array(dataa_test)\n",
    "y_test = np.array(tagg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STANDARDARIZING DATA # THIS CAUSES PROBLEM IN MAKING NETWORK\n",
    "# sc = StandardScaler()\n",
    " \n",
    "# x_train = sc.fit_transform(x_train)\n",
    "# x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(x_train)\n",
    "X_pca = pca.fit_transform(x_train)\n",
    "X_pca_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ica = X_pca\n",
    "X_ica_test = X_pca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKING 6 COMPONENTS\n",
    "\n",
    "ica = FastICA(n_components=6)\n",
    "X_ica = ica.fit_transform(x_train)\n",
    "X_ica_test = ica.transform(x_test)\n",
    "\n",
    "# X_ica = ica.fit_transform(X_pca)\n",
    "# X_ica_test = ica.transform(X_pca_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLYING DIFFERENT CLASSIFIERS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLYING RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_forest = RandomForestClassifier(max_depth=5, random_state = 0)\n",
    "r_forest.fit(X_ica,y_train)\n",
    "r_predicted = r_forest.predict(X_ica_test)\n",
    "score = r_forest.score(X_ica_test, y_test)\n",
    "rf_score_ = np.mean(score)\n",
    "\n",
    "print('Accuracy : %.3f' % (rf_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, r_predicted))\n",
    "print(classification_report(y_test, r_predicted))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLYING GRADIENT BOOSING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_boost = GradientBoostingClassifier(random_state=3)\n",
    "g_boost.fit(X_ica, y_train)\n",
    "predicted = g_boost.predict(X_ica_test)\n",
    "g_score = g_boost.score(X_ica_test, y_test)\n",
    "g_boost_score = np.mean(g_score)\n",
    "\n",
    "print('Accuracy : %.3f' % (g_boost_score*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, predicted))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLYING LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=3)\n",
    "log_reg.fit(X_ica, y_train)\n",
    "lg_predicted = log_reg.predict(X_ica_test)\n",
    "lg_score = log_reg.score(X_ica_test, y_test)\n",
    "lg_score_ = np.mean(lg_score)\n",
    "\n",
    "print('Accuracy : %.3f' % (lg_score_*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, lg_predicted))\n",
    "print(classification_report(y_test, lg_predicted))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLYING GAUSSION PROCSS REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GaussianProcessRegressor(random_state=2)\n",
    "gp.fit(X_ica, y_train)\n",
    "gp_score = gp.score(X_ica_test, y_test)\n",
    "gp_predicted = gp.predict(X_ica_test)\n",
    "gp_score_ = np.mean(gp_score)\n",
    "print('Accuracy : %.3f' % (gp_score_*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLING DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=6)\n",
    "dt.fit(X_ica, y_train)\n",
    "dt_score = dt.score(X_ica_test, y_test)\n",
    "predicted = dt.predict(X_ica_test)\n",
    "dt_score_ = np.mean(dt_score)\n",
    "\n",
    "print('Accuracy : %.3f' % (dt_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, predicted))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLYING SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(C=.3, kernel='poly', gamma=1)\n",
    "svc_model.fit(X_ica, y_train)\n",
    " \n",
    "prediction = svc_model.predict(X_ica_test)\n",
    "svc_score = svc_model.score(X_ica_test, y_test)\n",
    "svc_score_ = np.mean(svc_score)\n",
    "\n",
    "print('Accuracy : %.3f' % (svc_score_*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, prediction))\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLYING ADABOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=200, learning_rate=0.2, random_state=0)\n",
    "model = abc.fit(X_ica, y_train)\n",
    "\n",
    "y_pred = model.predict(X_ica_test)\n",
    "\n",
    "ada_score_ = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy : %.3f' % (ada_score_*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLYING KNN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "  \n",
    "knn.fit(X_ica, y_train)\n",
    "  \n",
    "# Predict on dataset which model has not seen before\n",
    "knn_p = knn.predict(X_ica_test)\n",
    "\n",
    "knn_score_ = np.mean(knn.score(X_ica_test, y_test))\n",
    "\n",
    "print('Accuracy : %.3f' % (knn_score_*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, knn_p))\n",
    "print(classification_report(y_test, knn_p))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARING CLASSIFICATION METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [rf_score_, g_boost_score, lg_score_, dt_score_, svc_score_, ada_score_, knn_score_ ]\n",
    "strr = \"rf_score_, g_boost_score, lg_score_, dt_score_, svc_score_, ada_acore_, knn_score_\"\n",
    "x_ax = [i for i in strr.split(\",\")]\n",
    "x = [i for i in range(len(x_ax))]\n",
    "\n",
    "scores = np.array(scores)*100\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "# plt.ylim([-1, 100])\n",
    "plt.xticks(x, x_ax)\n",
    "plt.plot(x, scores)\n",
    "plt.scatter(x, scores)\n",
    "for i, txt in enumerate(x_ax):\n",
    "    plt.annotate(txt, (x[i]-0.2 ,scores[i]+0.1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.bar(x_ax, scores)\n",
    "\n",
    "for i, txt in enumerate(scores):\n",
    "    plt.annotate(f\"{txt:.2f}%\", (x[i]-0.25 ,scores[i]+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergg_0 = np.array([]) \n",
    "mergg_0 = np.append(mergg_0, X_ica[:, 0])\n",
    "mergg_0 = np.append(mergg_0, X_ica_test[:, 0])\n",
    "\n",
    "mergg_1 = np.array([])\n",
    "mergg_1 = np.append(mergg_1, X_ica[:, 1])\n",
    "mergg_1 = np.append(mergg_1, X_ica_test[:, 1])\n",
    "\n",
    "mergg = np.array(list(zip(mergg_0, mergg_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_for_network = []\n",
    "points_for_network = mergg\n",
    "# points_for_network[:] = X_ica[:, 0:2] \n",
    "# points_for_network[:] = list(points_for_network_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(a, b, dis_type = 0):\n",
    "    '''\n",
    "    0 FOR MANHATTON DISTANCE\n",
    "    1 FOR EUCLEDIAN DISTANC\n",
    "    '''\n",
    "    summ = 0\n",
    "    diff = 0 \n",
    "    summs = []\n",
    "    diffs = []\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        diffs.append(np.abs(a[i] - b[i]))\n",
    "    \n",
    "    if dis_type:\n",
    "        return sum([i**2 for i in diffs])**0.5 # EUCLEDIAN DISTANCE \n",
    "    return sum(diffs) # MANHATTEN DISTANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distt = []\n",
    "for i, pointt in enumerate(points_for_network[:-1]):\n",
    "    for j, pointt_o in enumerate(points_for_network[i+1:]):\n",
    "        distt.append(get_distance(pointt_o, pointt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING\n",
    "np.mean(distt), max(distt), min(distt), np.std(distt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = list(sorted(distt, reverse=True))\n",
    "difff = []\n",
    "for i in range(len(dec)-1):\n",
    "    difff.append(dec[i] - dec[i+1])\n",
    "# print(sorted(difff, reverse= True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# ADDING NODES\n",
    "G.add_nodes_from([tuple(i,) for i in points_for_network])\n",
    "nodess = [i for i in G.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meann = np.mean(distt)\n",
    "_maxx = max(distt)\n",
    "for i in range(len(nodess)):\n",
    "    for j in range(len(nodess)):\n",
    "        _d = get_distance(nodess[i], nodess[j])\n",
    "        if i == j :\n",
    "            continue\n",
    "        # if _d >= _maxx :\n",
    "        #     continue\n",
    "        elif _d < meann:\n",
    "            G.add_edge(nodess[i], nodess[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 9))\n",
    "# nx.draw_networkx_edges(G, pos = pos, alpha=0.1)\n",
    "\n",
    "# IF WE STANDARIZE THE DATA, WE SHALL SEE 1 ISOLATED NODE.\n",
    "nx.draw(G, width = 0.5, node_size = 25, edge_color = \"black\", node_color = \"red\", label = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_diag = nx.diameter(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_degree_in_graph = [i for i in G.degree]\n",
    "# print(len(nodes_degree_in_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_x = list(set([i[1] for i in nodes_degree_in_graph]))\n",
    "# print(bar_x)\n",
    "plt.hist(bar_x, bins = 30)\n",
    "plt.show()\n",
    "net_avg_deg = np.average(bar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_avg_cluster = np.average([i[1] for i in list(dict(nx.clustering(G)).items())]) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In the network, it has {len(G.nodes)} nodes and it has {len(G.edges)} edges\")\n",
    "print(f\"Diameter of network : {net_diag}\")\n",
    "print(f\"Average degree : {net_avg_deg}\")\n",
    "print(f\"Average clustering : {net_avg_cluster}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=4) \n",
    "\n",
    "kmeans.fit(mergg)\n",
    "# kmeans.fit(x_train)\n",
    "\n",
    "# kmeans_predict = kmeans.predict(x_test)\n",
    "kmeans_predict = kmeans.predict(X_ica[:, 0:2])\n",
    "kmeans_predict_test = kmeans.predict(X_ica_test[:, 0:2])\n",
    "\n",
    "\n",
    "#y = Y_train.tolist()\n",
    "#labell = labels.tolist()\n",
    "labell = []\n",
    "labell[:] = [i for i in kmeans.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i for i in tagg.target]\n",
    "yy_test = [i for i in tagg_test.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels = 0\n",
    "for i in range(len(y)):\n",
    "        if(y[i] == labell[i]):\n",
    "                correct_labels += 1\n",
    "\n",
    "correct_labels_test = 0\n",
    "for i in range(len(yy_test)):\n",
    "        if(yy_test[i] == labell[i+len(y)]):\n",
    "                correct_labels_test += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels + correct_labels_test, tagg.size+tagg_test.size))\n",
    "print('Accuracy score: {0:0.2f}'.format((correct_labels+correct_labels_test)/(float(len(y)+len(yy_test)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_labels = np.unique(tagg)\n",
    "\n",
    "#plotting the results:\n",
    "plt.scatter(mergg[:, 0], mergg[:, 1], c = \"blue\", s = 50, label = \"original\", alpha=0.7)\n",
    "# plt.scatter(x_test[:, 0], x_test[:, 1], c = \"blue\", s = 100, label = \"original\", alpha=0.8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for i in u_labels:\n",
    "    plt.scatter(X_ica[:, 0], X_ica[:, 1], c = kmeans_predict, label = i)\n",
    "    plt.scatter(X_ica_test[:, 0], X_ica_test[:, 1], c = kmeans_predict_test, label = i)\n",
    "    # plt.scatter(x_test[:, 0], x_test[:, 1], c = kmeans_predict, label = i)\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GlobalEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37e1fb1bec1a71cc872f04cbae7efa28b150da833be6d20ef6d7d455e70be8c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
